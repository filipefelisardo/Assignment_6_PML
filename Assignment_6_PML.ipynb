{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXbAGECLuw8D9kyQeRCgnJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filipefelisardo/Assignment_6_PML/blob/main/Assignment_6_PML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDPn3ldXEWZq",
        "outputId": "aa1e1b0d-fcf7-46e5-b512-e09c5a5b864c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "            Conv2d-3           [-1, 32, 32, 32]           4,640\n",
            "              ReLU-4           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-5           [-1, 32, 16, 16]               0\n",
            "            Conv2d-6           [-1, 64, 16, 16]          18,496\n",
            "              ReLU-7           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-8             [-1, 64, 8, 8]               0\n",
            "           Flatten-9                 [-1, 4096]               0\n",
            "           Linear-10                  [-1, 256]       1,048,832\n",
            "      BatchNorm1d-11                  [-1, 256]             512\n",
            "             ReLU-12                  [-1, 256]               0\n",
            "          Dropout-13                  [-1, 256]               0\n",
            "           Linear-14                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 1,075,498\n",
            "Trainable params: 1,075,498\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.13\n",
            "Params size (MB): 4.10\n",
            "Estimated Total Size (MB): 5.25\n",
            "----------------------------------------------------------------\n",
            "Epoch [1/5], Loss: 0.8897\n",
            "Epoch [2/5], Loss: 0.6213\n",
            "Epoch [3/5], Loss: 0.7395\n",
            "Epoch [4/5], Loss: 0.6983\n",
            "Epoch [5/5], Loss: 0.6979\n",
            "Test Accuracy of the model on the 10000 test images: 75.23 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data and parameters\n",
        "batch_size = 128 #\n",
        "num_epochs = 5 #\n",
        "learning_rate = 0.001 #\n",
        "regularization_param = 0.001\n",
        "dropout_p = 0.2 #\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_dl = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "test_dl = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# CNN model\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64*8*8, 256),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=dropout_p),\n",
        "    nn.Linear(256, 10)\n",
        ")\n",
        "\n",
        "# Model description\n",
        "summary(model, (3, 32, 32))  # C, H, W for CIFAR-10\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=regularization_param)\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_dl):\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_dl:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    }
  ]
}